{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# library\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql.functions import * #col, to_date, unix_timestamp\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "import shutil\n",
    "from dateutil.relativedelta import relativedelta\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "#from DatabaseModule import DatabaseModule\n",
    "from datetime import datetime,timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql import functions as F\n",
    "#db=DatabaseModule()\n",
    "## library\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql.functions import * #col, to_date, unix_timestamp\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import shutil\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "from operator import add\n",
    "\n",
    "## Mias\n",
    "#from pyspark.context import SparkContext\n",
    "#from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import col, abs, sum # Solo me traigo tres funciones del paquete functions\n",
    "from pyspark.sql import functions as F # Me traigo todas las funciones del paquete functions\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "from numpy import array, ravel\n",
    "#from sklearn.neural_network import MLPRegressor\n",
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "def sqlread(txtsql):\n",
    "    \"\"\"\n",
    "    Carga los datos de una sql\n",
    "    \"\"\"\n",
    "    postgres_host = \"poolpostgresxl.marathon.mesos:5432\"  \n",
    "    postgres_db = \"mutua\"                            # change this with the database you want to connect\n",
    "\n",
    "    user = os.environ.get(\"JPY_USER\")\n",
    "\n",
    "    sslCert = spark.conf.get(\"spark.ssl.datastore.certPem.path\")\n",
    "    sslKey = spark.conf.get(\"spark.ssl.datastore.keyPKCS8.path\")\n",
    "    sslRootCert = spark.conf.get(\"spark.ssl.datastore.caPem.path\")\n",
    "\n",
    "    url = (\"jdbc:postgresql://{host}/{db}?user={user}&ssl=true&sslmode=verify-full&sslcert={sslCert}&sslrootcert={sslRootCert}&sslkey={sslKey}\"\n",
    "                  .format(sslCert=sslCert,\n",
    "                          sslKey=sslKey,\n",
    "                          sslRootCert=sslRootCert,\n",
    "                          user=user,\n",
    "                          host=postgres_host,\n",
    "                          db=postgres_db))\n",
    "\n",
    "\n",
    "    options = {\"driver\":\"org.postgresql.Driver\"}\n",
    "    rst = spark.read.format(\"jdbc\").options(url=url,dbtable=txtsql,properties=options).load()\n",
    "    return rst\n",
    "\n",
    "def unionAll(*dfs):\n",
    "    first, *rest = dfs  \n",
    "    return sqlContext.createDataFrame(\n",
    "        sc.union([df.rdd.repartition(50) for df in dfs]),\n",
    "        first.schema\n",
    "    )\n",
    "\n",
    "def printC(df, active = 1 ):\n",
    "    \"\"\"\n",
    "    Carga los datos de una sql\n",
    "    \"\"\"\n",
    "    if active == 1:\n",
    "        print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = sqlread(\"(select date_part('year', ets)*100+date_part('month', ets),  \\\n",
    "  params ->> 'anosCarnet' as params_anosCarnet, \\\n",
    "  params ->> 'antiguedadPoliza' as params_antiguedadPoliza, \\\n",
    "  params ->> 'combustibleVehiculo' as params_combustibleVehiculo, \\\n",
    "  params ->> 'dniSolicitante' as params_dniSolicitante, \\\n",
    "  params ->> 'frecuenciapago' as params_frecuenciapago, \\\n",
    "  params ->> 'lugarAparcamientoVehiculo' as params_lugarAparcamientoVehiculo, \\\n",
    "  params ->> 'nivelScoreRiesgoMorosidad' as params_nivelScoreRiesgoMorosidad, \\\n",
    "  params ->> 'ocasionalEdadConductor' as params_ocasionalEdadConductor, \\\n",
    "  params ->> 'ratingagmadrid' as params_ratingagmadrid, \\\n",
    "  params ->> 'scorepricing' as params_scorepricing, \\\n",
    "  params ->> 'usoCocheSolicitante' as params_usoCocheSolicitante, \\\n",
    "  params ->> 'anosCarnetAsegurado18' as params_anosCarnetAsegurado18, \\\n",
    "  params ->> 'anosPropiedadVehiculo' as params_anosPropiedadVehiculo, \\\n",
    "  params ->> 'antiguedadCiaSolicitante' as params_antiguedadCiaSolicitante,  \\\n",
    "  params ->> 'antiguedadVehiculo' as params_antiguedadVehiculo, \\\n",
    "  params ->> 'anyoentrada' as params_anyoentrada, \\\n",
    "  params ->> 'codigoPostalSolicitante' as params_codigoPostalSolicitante,  \\\n",
    "  params ->> 'crmCampanaCliente' as params_crmCampanaCliente, \\\n",
    "  params ->> 'crmPresentador' as params_crmPresentador, \\\n",
    "  params ->> 'diasContratacionSeguro' as params_diasContratacionSeguro,  \\\n",
    "  params ->> 'edadConductor' as params_edadConductor, \\\n",
    "  params ->> 'fraccionamiento' as params_fraccionamiento, \\\n",
    "  params ->> 'franquicia' as params_franquicia, \\\n",
    "  params ->> 'grupoMarcaModeloDanos' as params_grupoMarcaModeloDanos, \\\n",
    "  params ->> 'grupoMarcaModeloResponsabilidad' as params_grupoMarcaModeloResponsabilidad, \\\n",
    "  params ->> 'kilimetrosAnoSolicitante' as params_kilimetrosAnoSolicitante,       \\\n",
    "  params ->> 'marcaVehiculo' as params_marcaVehiculo, \\\n",
    "  params ->> 'mesNacimientoSolicitante' as params_mesNacimientoSolicitante, \\\n",
    "  params ->> 'modalidad' as params_modalidad,                      \\\n",
    "  params ->> 'nuevosMercados' as params_nuevosMercados, \\\n",
    "  params ->> 'numeroSiniestrosSolicitante' as params_numeroSiniestrosSolicitante, \\\n",
    "  params ->> 'ocasionalAnosCarnet' as params_ocasionalAnosCarnet,            \\\n",
    "  params ->> 'origenEjecucion' as params_origenEjecucion, \\\n",
    "  params ->> 'provinciaSolicitante' as params_provinciaSolicitante, \\\n",
    "  params ->> 'pvpAccesoriosVehiculo' as params_pvpAccesoriosVehiculo,          \\\n",
    "  params ->> 'relacionMutuaSolicitante' as params_relacionMutuaSolicitante, \\\n",
    "  params ->> 'relacionPesoPotenciaVehiculo' as params_relacionPesoPotenciaVehiculo, \\\n",
    "  params ->> 'scoreagregador' as params_scoreagregador,                 \\\n",
    "  params ->> 'scoreRiesgoMorosidad' as params_scoreRiesgoMorosidad, \\\n",
    "  params ->> 'tipoDocumentoSolicitante' as params_tipoDocumentoSolicitante, \\\n",
    "  params ->> 'tipoSeguro' as params_tipoSeguro,                     \\\n",
    "  params ->> 'vehiculoTipo' as params_vehiculoTipo, \\\n",
    "  params ->> 'vehiculoTipoTarifa' as params_vehiculoTipoTarifa,  \\\n",
    "            count(*) conteo \\\n",
    "                     from scoring.vt_pricing_dinamico \\\n",
    "                     group by 1, 2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\\\n",
    "                              21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44 ) t\")\n",
    "a.repartition(1).write.csv(\"/user/mutua/pricing.csv\",mode=\"overwrite\",sep= \";\",header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fichLocalaut='pricing.csv'\n",
    "fichNubeaut=\"/user/mutua/pricing.csv\"\n",
    "rutaLocal='/var/sds/homes/mallo4l/workspace/shared/maa/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995473 /var/sds/homes/mallo4l/workspace/shared/maa/pricing.csv\n"
     ]
    }
   ],
   "source": [
    "%%sh -s $fichLocalaut $rutaLocal $fichNubeaut\n",
    "rm -rf $2$1\n",
    "KRB5CCNAME=FILE:/tmp/$JPY_USER_UID/krb5cc_$JPY_USER_UID hadoop fs -copyToLocal $3 $2$1 \n",
    "mv $2$1/part* $2data_csv\n",
    "rm -rf $2$1\n",
    "mv $2data_csv $2$1\n",
    "wc -l $2$1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark Python3 - Spark 2.2.0",
   "language": "python",
   "name": "spark2python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
